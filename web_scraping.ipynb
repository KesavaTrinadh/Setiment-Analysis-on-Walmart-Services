{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "rc6Zheqr_4UK",
        "GoDESFb2ABML",
        "dPFiKGqNALN2",
        "R7yHF09iC7gn",
        "RrVFS8gBEIQV",
        "rKenR1vBFNJi"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MlBeGRT05dnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 111 TO 253 PAGES"
      ],
      "metadata": {
        "id": "rc6Zheqr_4UK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cFWPG4MW5dqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import sleep\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 111\n",
        "to_page = 411\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "}  # Added headers to prevent request blocking\n",
        "\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    result = requests.get(url, headers=headers)\n",
        "\n",
        "    if result.status_code != 200:\n",
        "        print(f\"Failed to retrieve page {i}. Status code: {result.status_code}\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Locations (Only country, excluding review count)\n",
        "    soup2list(soup.find_all('span', class_='typography_body-m__k2UI7 typography_appearance-subtle__PYOVM'), locations)\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "locations += [\"N/A\"] * (max_length - len(locations))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Location': locations,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# # Optionally save to CSV\n",
        "# review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hi52OddA5dt0",
        "outputId": "234b6210-495b-4e42-980d-f9285873814f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve page 254. Status code: 403\n",
            "Failed to retrieve page 255. Status code: 403\n",
            "Failed to retrieve page 256. Status code: 403\n",
            "Failed to retrieve page 257. Status code: 403\n",
            "Failed to retrieve page 258. Status code: 403\n",
            "Failed to retrieve page 259. Status code: 403\n",
            "Failed to retrieve page 260. Status code: 403\n",
            "Failed to retrieve page 261. Status code: 403\n",
            "Failed to retrieve page 262. Status code: 403\n",
            "Failed to retrieve page 263. Status code: 403\n",
            "Failed to retrieve page 264. Status code: 403\n",
            "Failed to retrieve page 265. Status code: 403\n",
            "Failed to retrieve page 266. Status code: 403\n",
            "Failed to retrieve page 267. Status code: 403\n",
            "Failed to retrieve page 268. Status code: 403\n",
            "Failed to retrieve page 269. Status code: 403\n",
            "Failed to retrieve page 270. Status code: 403\n",
            "Failed to retrieve page 271. Status code: 403\n",
            "Failed to retrieve page 272. Status code: 403\n",
            "Failed to retrieve page 273. Status code: 403\n",
            "Failed to retrieve page 274. Status code: 403\n",
            "Failed to retrieve page 275. Status code: 403\n",
            "Failed to retrieve page 276. Status code: 403\n",
            "Failed to retrieve page 277. Status code: 403\n",
            "Failed to retrieve page 278. Status code: 403\n",
            "Failed to retrieve page 279. Status code: 403\n",
            "Failed to retrieve page 280. Status code: 403\n",
            "Failed to retrieve page 281. Status code: 403\n",
            "Failed to retrieve page 282. Status code: 403\n",
            "Failed to retrieve page 283. Status code: 403\n",
            "Failed to retrieve page 284. Status code: 403\n",
            "Failed to retrieve page 285. Status code: 403\n",
            "Failed to retrieve page 286. Status code: 403\n",
            "Failed to retrieve page 287. Status code: 403\n",
            "Failed to retrieve page 288. Status code: 403\n",
            "Failed to retrieve page 289. Status code: 403\n",
            "Failed to retrieve page 290. Status code: 403\n",
            "Failed to retrieve page 291. Status code: 403\n",
            "Failed to retrieve page 292. Status code: 403\n",
            "Failed to retrieve page 293. Status code: 403\n",
            "Failed to retrieve page 294. Status code: 403\n",
            "Failed to retrieve page 295. Status code: 403\n",
            "Failed to retrieve page 296. Status code: 403\n",
            "Failed to retrieve page 297. Status code: 403\n",
            "Failed to retrieve page 298. Status code: 403\n",
            "Failed to retrieve page 299. Status code: 403\n",
            "Failed to retrieve page 300. Status code: 403\n",
            "Failed to retrieve page 301. Status code: 403\n",
            "Failed to retrieve page 302. Status code: 403\n",
            "Failed to retrieve page 303. Status code: 403\n",
            "Failed to retrieve page 304. Status code: 403\n",
            "Failed to retrieve page 305. Status code: 403\n",
            "Failed to retrieve page 306. Status code: 403\n",
            "Failed to retrieve page 307. Status code: 403\n",
            "Failed to retrieve page 308. Status code: 403\n",
            "Failed to retrieve page 309. Status code: 403\n",
            "Failed to retrieve page 310. Status code: 403\n",
            "Failed to retrieve page 311. Status code: 403\n",
            "Failed to retrieve page 312. Status code: 403\n",
            "Failed to retrieve page 313. Status code: 403\n",
            "Failed to retrieve page 314. Status code: 403\n",
            "Failed to retrieve page 315. Status code: 403\n",
            "Failed to retrieve page 316. Status code: 403\n",
            "Failed to retrieve page 317. Status code: 403\n",
            "Failed to retrieve page 318. Status code: 403\n",
            "Failed to retrieve page 319. Status code: 403\n",
            "Failed to retrieve page 320. Status code: 403\n",
            "Failed to retrieve page 321. Status code: 403\n",
            "Failed to retrieve page 322. Status code: 403\n",
            "Failed to retrieve page 323. Status code: 403\n",
            "Failed to retrieve page 324. Status code: 403\n",
            "Failed to retrieve page 325. Status code: 403\n",
            "Failed to retrieve page 326. Status code: 403\n",
            "Failed to retrieve page 327. Status code: 403\n",
            "Failed to retrieve page 328. Status code: 403\n",
            "Failed to retrieve page 329. Status code: 403\n",
            "Failed to retrieve page 330. Status code: 403\n",
            "Failed to retrieve page 331. Status code: 403\n",
            "Failed to retrieve page 332. Status code: 403\n",
            "Failed to retrieve page 333. Status code: 403\n",
            "Failed to retrieve page 334. Status code: 403\n",
            "Failed to retrieve page 335. Status code: 403\n",
            "Failed to retrieve page 336. Status code: 403\n",
            "Failed to retrieve page 337. Status code: 403\n",
            "Failed to retrieve page 338. Status code: 403\n",
            "Failed to retrieve page 339. Status code: 403\n",
            "Failed to retrieve page 340. Status code: 403\n",
            "Failed to retrieve page 341. Status code: 403\n",
            "Failed to retrieve page 342. Status code: 403\n",
            "Failed to retrieve page 343. Status code: 403\n",
            "Failed to retrieve page 344. Status code: 403\n",
            "Failed to retrieve page 345. Status code: 403\n",
            "Failed to retrieve page 346. Status code: 403\n",
            "Failed to retrieve page 347. Status code: 403\n",
            "Failed to retrieve page 348. Status code: 403\n",
            "Failed to retrieve page 349. Status code: 403\n",
            "Failed to retrieve page 350. Status code: 403\n",
            "Failed to retrieve page 351. Status code: 403\n",
            "Failed to retrieve page 352. Status code: 403\n",
            "Failed to retrieve page 353. Status code: 403\n",
            "Failed to retrieve page 354. Status code: 403\n",
            "Failed to retrieve page 355. Status code: 403\n",
            "Failed to retrieve page 356. Status code: 403\n",
            "Failed to retrieve page 357. Status code: 403\n",
            "Failed to retrieve page 358. Status code: 403\n",
            "Failed to retrieve page 359. Status code: 403\n",
            "Failed to retrieve page 360. Status code: 403\n",
            "Failed to retrieve page 361. Status code: 403\n",
            "Failed to retrieve page 362. Status code: 403\n",
            "Failed to retrieve page 363. Status code: 403\n",
            "Failed to retrieve page 364. Status code: 403\n",
            "Failed to retrieve page 365. Status code: 403\n",
            "Failed to retrieve page 366. Status code: 403\n",
            "Failed to retrieve page 367. Status code: 403\n",
            "Failed to retrieve page 368. Status code: 403\n",
            "Failed to retrieve page 369. Status code: 403\n",
            "Failed to retrieve page 370. Status code: 403\n",
            "Failed to retrieve page 371. Status code: 403\n",
            "Failed to retrieve page 372. Status code: 403\n",
            "Failed to retrieve page 373. Status code: 403\n",
            "Failed to retrieve page 374. Status code: 403\n",
            "Failed to retrieve page 375. Status code: 403\n",
            "Failed to retrieve page 376. Status code: 403\n",
            "Failed to retrieve page 377. Status code: 403\n",
            "Failed to retrieve page 378. Status code: 403\n",
            "Failed to retrieve page 379. Status code: 403\n",
            "Failed to retrieve page 380. Status code: 403\n",
            "Failed to retrieve page 381. Status code: 403\n",
            "Failed to retrieve page 382. Status code: 403\n",
            "Failed to retrieve page 383. Status code: 403\n",
            "Failed to retrieve page 384. Status code: 403\n",
            "Failed to retrieve page 385. Status code: 403\n",
            "Failed to retrieve page 386. Status code: 403\n",
            "Failed to retrieve page 387. Status code: 403\n",
            "Failed to retrieve page 388. Status code: 403\n",
            "Failed to retrieve page 389. Status code: 403\n",
            "Failed to retrieve page 390. Status code: 403\n",
            "Failed to retrieve page 391. Status code: 403\n",
            "Failed to retrieve page 392. Status code: 403\n",
            "Failed to retrieve page 393. Status code: 403\n",
            "Failed to retrieve page 394. Status code: 403\n",
            "Failed to retrieve page 395. Status code: 403\n",
            "Failed to retrieve page 396. Status code: 403\n",
            "Failed to retrieve page 397. Status code: 403\n",
            "Failed to retrieve page 398. Status code: 403\n",
            "Failed to retrieve page 399. Status code: 403\n",
            "Failed to retrieve page 400. Status code: 403\n",
            "Failed to retrieve page 401. Status code: 403\n",
            "Failed to retrieve page 402. Status code: 403\n",
            "Failed to retrieve page 403. Status code: 403\n",
            "Failed to retrieve page 404. Status code: 403\n",
            "Failed to retrieve page 405. Status code: 403\n",
            "Failed to retrieve page 406. Status code: 403\n",
            "Failed to retrieve page 407. Status code: 403\n",
            "Failed to retrieve page 408. Status code: 403\n",
            "Failed to retrieve page 409. Status code: 403\n",
            "Failed to retrieve page 410. Status code: 403\n",
            "Failed to retrieve page 411. Status code: 403\n",
            "          Username Total reviews      Location                      Date  \\\n",
            "0                              3   37K reviews  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             2  3.7K reviews  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            18   15K reviews  2025-03-11T02:19:00.000Z   \n",
            "3               LA             4       Summary  2025-03-08T00:41:55.000Z   \n",
            "4           Laurie             7         About  2023-04-01T00:08:41.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  It's WalmartIt's Walmart, products are usually...      3  \n",
            "1  I ordered a Easter shirt an pants for…I ordere...      1  \n",
            "2  One star because there was nothing…One star be...      1  \n",
            "3  I placed an order order of March 22I placed an...      1  \n",
            "4  Online order delivered to wrong address and re...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lyBrRMLp5d1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 254 TO 391 PAGES"
      ],
      "metadata": {
        "id": "GoDESFb2ABML"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2FLp-175d-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 254\n",
        "to_page = 411\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "# List of user-agents to simulate different browsers\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n",
        "]\n",
        "\n",
        "# Function to fetch a page with retries in case of failure\n",
        "def fetch_page_with_retry(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        headers = {\n",
        "            \"User-Agent\": random.choice(user_agents)\n",
        "        }\n",
        "        try:\n",
        "            result = requests.get(url, headers=headers)\n",
        "            if result.status_code == 200:\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Failed to retrieve page. Status code: {result.status_code}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for {url}: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"Failed to retrieve {url} after {retries} retries.\")\n",
        "    return None  # Return None if all retries fail\n",
        "\n",
        "# Scraping the reviews from page 111 to 411\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    print(f\"Fetching page {i}: {url}\")\n",
        "\n",
        "    # Fetch the page with retry mechanism\n",
        "    result = fetch_page_with_retry(url)\n",
        "\n",
        "    if not result:\n",
        "        print(f\"Skipping page {i} due to repeated failures.\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Locations (Only country, excluding review count)\n",
        "    soup2list(soup.find_all('span', class_='typography_body-m__k2UI7 typography_appearance-subtle__PYOVM'), locations)\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "locations += [\"N/A\"] * (max_length - len(locations))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Location': locations,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# Optionally save to CSV\n",
        "review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8XYr8bK77G8",
        "outputId": "1aeac45c-e0ba-46cc-ca3a-6d0e3250ccdf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 254: https://www.trustpilot.com/review/www.walmart.com?page=254\n",
            "Fetching page 255: https://www.trustpilot.com/review/www.walmart.com?page=255\n",
            "Fetching page 256: https://www.trustpilot.com/review/www.walmart.com?page=256\n",
            "Fetching page 257: https://www.trustpilot.com/review/www.walmart.com?page=257\n",
            "Fetching page 258: https://www.trustpilot.com/review/www.walmart.com?page=258\n",
            "Fetching page 259: https://www.trustpilot.com/review/www.walmart.com?page=259\n",
            "Fetching page 260: https://www.trustpilot.com/review/www.walmart.com?page=260\n",
            "Fetching page 261: https://www.trustpilot.com/review/www.walmart.com?page=261\n",
            "Fetching page 262: https://www.trustpilot.com/review/www.walmart.com?page=262\n",
            "Fetching page 263: https://www.trustpilot.com/review/www.walmart.com?page=263\n",
            "Fetching page 264: https://www.trustpilot.com/review/www.walmart.com?page=264\n",
            "Fetching page 265: https://www.trustpilot.com/review/www.walmart.com?page=265\n",
            "Fetching page 266: https://www.trustpilot.com/review/www.walmart.com?page=266\n",
            "Fetching page 267: https://www.trustpilot.com/review/www.walmart.com?page=267\n",
            "Fetching page 268: https://www.trustpilot.com/review/www.walmart.com?page=268\n",
            "Fetching page 269: https://www.trustpilot.com/review/www.walmart.com?page=269\n",
            "Fetching page 270: https://www.trustpilot.com/review/www.walmart.com?page=270\n",
            "Fetching page 271: https://www.trustpilot.com/review/www.walmart.com?page=271\n",
            "Fetching page 272: https://www.trustpilot.com/review/www.walmart.com?page=272\n",
            "Fetching page 273: https://www.trustpilot.com/review/www.walmart.com?page=273\n",
            "Fetching page 274: https://www.trustpilot.com/review/www.walmart.com?page=274\n",
            "Fetching page 275: https://www.trustpilot.com/review/www.walmart.com?page=275\n",
            "Fetching page 276: https://www.trustpilot.com/review/www.walmart.com?page=276\n",
            "Fetching page 277: https://www.trustpilot.com/review/www.walmart.com?page=277\n",
            "Fetching page 278: https://www.trustpilot.com/review/www.walmart.com?page=278\n",
            "Fetching page 279: https://www.trustpilot.com/review/www.walmart.com?page=279\n",
            "Fetching page 280: https://www.trustpilot.com/review/www.walmart.com?page=280\n",
            "Fetching page 281: https://www.trustpilot.com/review/www.walmart.com?page=281\n",
            "Fetching page 282: https://www.trustpilot.com/review/www.walmart.com?page=282\n",
            "Fetching page 283: https://www.trustpilot.com/review/www.walmart.com?page=283\n",
            "Fetching page 284: https://www.trustpilot.com/review/www.walmart.com?page=284\n",
            "Fetching page 285: https://www.trustpilot.com/review/www.walmart.com?page=285\n",
            "Fetching page 286: https://www.trustpilot.com/review/www.walmart.com?page=286\n",
            "Fetching page 287: https://www.trustpilot.com/review/www.walmart.com?page=287\n",
            "Fetching page 288: https://www.trustpilot.com/review/www.walmart.com?page=288\n",
            "Fetching page 289: https://www.trustpilot.com/review/www.walmart.com?page=289\n",
            "Fetching page 290: https://www.trustpilot.com/review/www.walmart.com?page=290\n",
            "Fetching page 291: https://www.trustpilot.com/review/www.walmart.com?page=291\n",
            "Fetching page 292: https://www.trustpilot.com/review/www.walmart.com?page=292\n",
            "Fetching page 293: https://www.trustpilot.com/review/www.walmart.com?page=293\n",
            "Fetching page 294: https://www.trustpilot.com/review/www.walmart.com?page=294\n",
            "Fetching page 295: https://www.trustpilot.com/review/www.walmart.com?page=295\n",
            "Fetching page 296: https://www.trustpilot.com/review/www.walmart.com?page=296\n",
            "Fetching page 297: https://www.trustpilot.com/review/www.walmart.com?page=297\n",
            "Fetching page 298: https://www.trustpilot.com/review/www.walmart.com?page=298\n",
            "Fetching page 299: https://www.trustpilot.com/review/www.walmart.com?page=299\n",
            "Fetching page 300: https://www.trustpilot.com/review/www.walmart.com?page=300\n",
            "Fetching page 301: https://www.trustpilot.com/review/www.walmart.com?page=301\n",
            "Fetching page 302: https://www.trustpilot.com/review/www.walmart.com?page=302\n",
            "Fetching page 303: https://www.trustpilot.com/review/www.walmart.com?page=303\n",
            "Fetching page 304: https://www.trustpilot.com/review/www.walmart.com?page=304\n",
            "Fetching page 305: https://www.trustpilot.com/review/www.walmart.com?page=305\n",
            "Fetching page 306: https://www.trustpilot.com/review/www.walmart.com?page=306\n",
            "Fetching page 307: https://www.trustpilot.com/review/www.walmart.com?page=307\n",
            "Fetching page 308: https://www.trustpilot.com/review/www.walmart.com?page=308\n",
            "Fetching page 309: https://www.trustpilot.com/review/www.walmart.com?page=309\n",
            "Fetching page 310: https://www.trustpilot.com/review/www.walmart.com?page=310\n",
            "Fetching page 311: https://www.trustpilot.com/review/www.walmart.com?page=311\n",
            "Fetching page 312: https://www.trustpilot.com/review/www.walmart.com?page=312\n",
            "Fetching page 313: https://www.trustpilot.com/review/www.walmart.com?page=313\n",
            "Fetching page 314: https://www.trustpilot.com/review/www.walmart.com?page=314\n",
            "Fetching page 315: https://www.trustpilot.com/review/www.walmart.com?page=315\n",
            "Fetching page 316: https://www.trustpilot.com/review/www.walmart.com?page=316\n",
            "Fetching page 317: https://www.trustpilot.com/review/www.walmart.com?page=317\n",
            "Fetching page 318: https://www.trustpilot.com/review/www.walmart.com?page=318\n",
            "Fetching page 319: https://www.trustpilot.com/review/www.walmart.com?page=319\n",
            "Fetching page 320: https://www.trustpilot.com/review/www.walmart.com?page=320\n",
            "Fetching page 321: https://www.trustpilot.com/review/www.walmart.com?page=321\n",
            "Fetching page 322: https://www.trustpilot.com/review/www.walmart.com?page=322\n",
            "Fetching page 323: https://www.trustpilot.com/review/www.walmart.com?page=323\n",
            "Fetching page 324: https://www.trustpilot.com/review/www.walmart.com?page=324\n",
            "Fetching page 325: https://www.trustpilot.com/review/www.walmart.com?page=325\n",
            "Fetching page 326: https://www.trustpilot.com/review/www.walmart.com?page=326\n",
            "Fetching page 327: https://www.trustpilot.com/review/www.walmart.com?page=327\n",
            "Fetching page 328: https://www.trustpilot.com/review/www.walmart.com?page=328\n",
            "Fetching page 329: https://www.trustpilot.com/review/www.walmart.com?page=329\n",
            "Fetching page 330: https://www.trustpilot.com/review/www.walmart.com?page=330\n",
            "Fetching page 331: https://www.trustpilot.com/review/www.walmart.com?page=331\n",
            "Fetching page 332: https://www.trustpilot.com/review/www.walmart.com?page=332\n",
            "Fetching page 333: https://www.trustpilot.com/review/www.walmart.com?page=333\n",
            "Fetching page 334: https://www.trustpilot.com/review/www.walmart.com?page=334\n",
            "Fetching page 335: https://www.trustpilot.com/review/www.walmart.com?page=335\n",
            "Fetching page 336: https://www.trustpilot.com/review/www.walmart.com?page=336\n",
            "Fetching page 337: https://www.trustpilot.com/review/www.walmart.com?page=337\n",
            "Fetching page 338: https://www.trustpilot.com/review/www.walmart.com?page=338\n",
            "Fetching page 339: https://www.trustpilot.com/review/www.walmart.com?page=339\n",
            "Fetching page 340: https://www.trustpilot.com/review/www.walmart.com?page=340\n",
            "Fetching page 341: https://www.trustpilot.com/review/www.walmart.com?page=341\n",
            "Fetching page 342: https://www.trustpilot.com/review/www.walmart.com?page=342\n",
            "Fetching page 343: https://www.trustpilot.com/review/www.walmart.com?page=343\n",
            "Fetching page 344: https://www.trustpilot.com/review/www.walmart.com?page=344\n",
            "Fetching page 345: https://www.trustpilot.com/review/www.walmart.com?page=345\n",
            "Fetching page 346: https://www.trustpilot.com/review/www.walmart.com?page=346\n",
            "Fetching page 347: https://www.trustpilot.com/review/www.walmart.com?page=347\n",
            "Fetching page 348: https://www.trustpilot.com/review/www.walmart.com?page=348\n",
            "Fetching page 349: https://www.trustpilot.com/review/www.walmart.com?page=349\n",
            "Fetching page 350: https://www.trustpilot.com/review/www.walmart.com?page=350\n",
            "Fetching page 351: https://www.trustpilot.com/review/www.walmart.com?page=351\n",
            "Fetching page 352: https://www.trustpilot.com/review/www.walmart.com?page=352\n",
            "Fetching page 353: https://www.trustpilot.com/review/www.walmart.com?page=353\n",
            "Fetching page 354: https://www.trustpilot.com/review/www.walmart.com?page=354\n",
            "Fetching page 355: https://www.trustpilot.com/review/www.walmart.com?page=355\n",
            "Fetching page 356: https://www.trustpilot.com/review/www.walmart.com?page=356\n",
            "Fetching page 357: https://www.trustpilot.com/review/www.walmart.com?page=357\n",
            "Fetching page 358: https://www.trustpilot.com/review/www.walmart.com?page=358\n",
            "Fetching page 359: https://www.trustpilot.com/review/www.walmart.com?page=359\n",
            "Fetching page 360: https://www.trustpilot.com/review/www.walmart.com?page=360\n",
            "Fetching page 361: https://www.trustpilot.com/review/www.walmart.com?page=361\n",
            "Fetching page 362: https://www.trustpilot.com/review/www.walmart.com?page=362\n",
            "Fetching page 363: https://www.trustpilot.com/review/www.walmart.com?page=363\n",
            "Fetching page 364: https://www.trustpilot.com/review/www.walmart.com?page=364\n",
            "Fetching page 365: https://www.trustpilot.com/review/www.walmart.com?page=365\n",
            "Fetching page 366: https://www.trustpilot.com/review/www.walmart.com?page=366\n",
            "Fetching page 367: https://www.trustpilot.com/review/www.walmart.com?page=367\n",
            "Fetching page 368: https://www.trustpilot.com/review/www.walmart.com?page=368\n",
            "Fetching page 369: https://www.trustpilot.com/review/www.walmart.com?page=369\n",
            "Fetching page 370: https://www.trustpilot.com/review/www.walmart.com?page=370\n",
            "Fetching page 371: https://www.trustpilot.com/review/www.walmart.com?page=371\n",
            "Fetching page 372: https://www.trustpilot.com/review/www.walmart.com?page=372\n",
            "Fetching page 373: https://www.trustpilot.com/review/www.walmart.com?page=373\n",
            "Fetching page 374: https://www.trustpilot.com/review/www.walmart.com?page=374\n",
            "Fetching page 375: https://www.trustpilot.com/review/www.walmart.com?page=375\n",
            "Fetching page 376: https://www.trustpilot.com/review/www.walmart.com?page=376\n",
            "Fetching page 377: https://www.trustpilot.com/review/www.walmart.com?page=377\n",
            "Fetching page 378: https://www.trustpilot.com/review/www.walmart.com?page=378\n",
            "Fetching page 379: https://www.trustpilot.com/review/www.walmart.com?page=379\n",
            "Fetching page 380: https://www.trustpilot.com/review/www.walmart.com?page=380\n",
            "Fetching page 381: https://www.trustpilot.com/review/www.walmart.com?page=381\n",
            "Fetching page 382: https://www.trustpilot.com/review/www.walmart.com?page=382\n",
            "Fetching page 383: https://www.trustpilot.com/review/www.walmart.com?page=383\n",
            "Fetching page 384: https://www.trustpilot.com/review/www.walmart.com?page=384\n",
            "Fetching page 385: https://www.trustpilot.com/review/www.walmart.com?page=385\n",
            "Fetching page 386: https://www.trustpilot.com/review/www.walmart.com?page=386\n",
            "Fetching page 387: https://www.trustpilot.com/review/www.walmart.com?page=387\n",
            "Fetching page 388: https://www.trustpilot.com/review/www.walmart.com?page=388\n",
            "Fetching page 389: https://www.trustpilot.com/review/www.walmart.com?page=389\n",
            "Fetching page 390: https://www.trustpilot.com/review/www.walmart.com?page=390\n",
            "Fetching page 391: https://www.trustpilot.com/review/www.walmart.com?page=391\n",
            "Fetching page 392: https://www.trustpilot.com/review/www.walmart.com?page=392\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=392 after 5 retries.\n",
            "Skipping page 392 due to repeated failures.\n",
            "Fetching page 393: https://www.trustpilot.com/review/www.walmart.com?page=393\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=393 after 5 retries.\n",
            "Skipping page 393 due to repeated failures.\n",
            "Fetching page 394: https://www.trustpilot.com/review/www.walmart.com?page=394\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=394 after 5 retries.\n",
            "Skipping page 394 due to repeated failures.\n",
            "Fetching page 395: https://www.trustpilot.com/review/www.walmart.com?page=395\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=395 after 5 retries.\n",
            "Skipping page 395 due to repeated failures.\n",
            "Fetching page 396: https://www.trustpilot.com/review/www.walmart.com?page=396\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=396 after 5 retries.\n",
            "Skipping page 396 due to repeated failures.\n",
            "Fetching page 397: https://www.trustpilot.com/review/www.walmart.com?page=397\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve page. Status code: 403. Retrying...\n",
            "Failed to retrieve https://www.trustpilot.com/review/www.walmart.com?page=397 after 5 retries.\n",
            "Skipping page 397 due to repeated failures.\n",
            "Fetching page 398: https://www.trustpilot.com/review/www.walmart.com?page=398\n",
            "Fetching page 399: https://www.trustpilot.com/review/www.walmart.com?page=399\n",
            "Fetching page 400: https://www.trustpilot.com/review/www.walmart.com?page=400\n",
            "Fetching page 401: https://www.trustpilot.com/review/www.walmart.com?page=401\n",
            "Fetching page 402: https://www.trustpilot.com/review/www.walmart.com?page=402\n",
            "Fetching page 403: https://www.trustpilot.com/review/www.walmart.com?page=403\n",
            "Fetching page 404: https://www.trustpilot.com/review/www.walmart.com?page=404\n",
            "Fetching page 405: https://www.trustpilot.com/review/www.walmart.com?page=405\n",
            "Fetching page 406: https://www.trustpilot.com/review/www.walmart.com?page=406\n",
            "Fetching page 407: https://www.trustpilot.com/review/www.walmart.com?page=407\n",
            "Fetching page 408: https://www.trustpilot.com/review/www.walmart.com?page=408\n",
            "Fetching page 409: https://www.trustpilot.com/review/www.walmart.com?page=409\n",
            "Fetching page 410: https://www.trustpilot.com/review/www.walmart.com?page=410\n",
            "Fetching page 411: https://www.trustpilot.com/review/www.walmart.com?page=411\n",
            "          Username Total reviews      Location                      Date  \\\n",
            "0                              3   37K reviews  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             3  3.7K reviews  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            18   15K reviews  2025-03-11T02:19:00.000Z   \n",
            "3               LA            11       Summary  2025-03-11T20:29:17.000Z   \n",
            "4           Laurie             1         About  2021-08-13T17:43:16.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  Walmart Store Vidor - Great Customer ServiceWa...      5  \n",
            "1  Buyer beware on electronic and exercise equipm...      1  \n",
            "2  Worthless CompanyEvery time I place a order on...      1  \n",
            "3  They dont do same day delivery and I…They dont...      2  \n",
            "4  Walmart is crapWalmart is crap. Going to stop ...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HH_xZbmT_G8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HnRPY9sk_HAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 392 TO 513 PAGES"
      ],
      "metadata": {
        "id": "dPFiKGqNALN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 392\n",
        "to_page = 513\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "# List of user-agents to simulate different browsers\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n",
        "]\n",
        "\n",
        "# Function to fetch a page with retries in case of failure\n",
        "def fetch_page_with_retry(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        headers = {\n",
        "            \"User-Agent\": random.choice(user_agents)\n",
        "        }\n",
        "        try:\n",
        "            result = requests.get(url, headers=headers)\n",
        "            if result.status_code == 200:\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Failed to retrieve page. Status code: {result.status_code}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for {url}: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"Failed to retrieve {url} after {retries} retries.\")\n",
        "    return None  # Return None if all retries fail\n",
        "\n",
        "# Scraping the reviews from page 111 to 411\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    print(f\"Fetching page {i}: {url}\")\n",
        "\n",
        "    # Fetch the page with retry mechanism\n",
        "    result = fetch_page_with_retry(url)\n",
        "\n",
        "    if not result:\n",
        "        print(f\"Skipping page {i} due to repeated failures.\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# # Optionally save to CSV\n",
        "# review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9wQ9-J577J_",
        "outputId": "116ecfa7-4628-4cde-a9d9-79d8841e48ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 392: https://www.trustpilot.com/review/www.walmart.com?page=392\n",
            "Fetching page 393: https://www.trustpilot.com/review/www.walmart.com?page=393\n",
            "Fetching page 394: https://www.trustpilot.com/review/www.walmart.com?page=394\n",
            "Fetching page 395: https://www.trustpilot.com/review/www.walmart.com?page=395\n",
            "Fetching page 396: https://www.trustpilot.com/review/www.walmart.com?page=396\n",
            "Fetching page 397: https://www.trustpilot.com/review/www.walmart.com?page=397\n",
            "Fetching page 398: https://www.trustpilot.com/review/www.walmart.com?page=398\n",
            "Fetching page 399: https://www.trustpilot.com/review/www.walmart.com?page=399\n",
            "Fetching page 400: https://www.trustpilot.com/review/www.walmart.com?page=400\n",
            "Fetching page 401: https://www.trustpilot.com/review/www.walmart.com?page=401\n",
            "Fetching page 402: https://www.trustpilot.com/review/www.walmart.com?page=402\n",
            "Fetching page 403: https://www.trustpilot.com/review/www.walmart.com?page=403\n",
            "Fetching page 404: https://www.trustpilot.com/review/www.walmart.com?page=404\n",
            "Fetching page 405: https://www.trustpilot.com/review/www.walmart.com?page=405\n",
            "Fetching page 406: https://www.trustpilot.com/review/www.walmart.com?page=406\n",
            "Fetching page 407: https://www.trustpilot.com/review/www.walmart.com?page=407\n",
            "Fetching page 408: https://www.trustpilot.com/review/www.walmart.com?page=408\n",
            "Fetching page 409: https://www.trustpilot.com/review/www.walmart.com?page=409\n",
            "Fetching page 410: https://www.trustpilot.com/review/www.walmart.com?page=410\n",
            "Fetching page 411: https://www.trustpilot.com/review/www.walmart.com?page=411\n",
            "Fetching page 412: https://www.trustpilot.com/review/www.walmart.com?page=412\n",
            "Fetching page 413: https://www.trustpilot.com/review/www.walmart.com?page=413\n",
            "Fetching page 414: https://www.trustpilot.com/review/www.walmart.com?page=414\n",
            "Fetching page 415: https://www.trustpilot.com/review/www.walmart.com?page=415\n",
            "Fetching page 416: https://www.trustpilot.com/review/www.walmart.com?page=416\n",
            "Fetching page 417: https://www.trustpilot.com/review/www.walmart.com?page=417\n",
            "Fetching page 418: https://www.trustpilot.com/review/www.walmart.com?page=418\n",
            "Fetching page 419: https://www.trustpilot.com/review/www.walmart.com?page=419\n",
            "Fetching page 420: https://www.trustpilot.com/review/www.walmart.com?page=420\n",
            "Fetching page 421: https://www.trustpilot.com/review/www.walmart.com?page=421\n",
            "Fetching page 422: https://www.trustpilot.com/review/www.walmart.com?page=422\n",
            "Fetching page 423: https://www.trustpilot.com/review/www.walmart.com?page=423\n",
            "Fetching page 424: https://www.trustpilot.com/review/www.walmart.com?page=424\n",
            "Fetching page 425: https://www.trustpilot.com/review/www.walmart.com?page=425\n",
            "Fetching page 426: https://www.trustpilot.com/review/www.walmart.com?page=426\n",
            "Fetching page 427: https://www.trustpilot.com/review/www.walmart.com?page=427\n",
            "Fetching page 428: https://www.trustpilot.com/review/www.walmart.com?page=428\n",
            "Fetching page 429: https://www.trustpilot.com/review/www.walmart.com?page=429\n",
            "Fetching page 430: https://www.trustpilot.com/review/www.walmart.com?page=430\n",
            "Fetching page 431: https://www.trustpilot.com/review/www.walmart.com?page=431\n",
            "Fetching page 432: https://www.trustpilot.com/review/www.walmart.com?page=432\n",
            "Fetching page 433: https://www.trustpilot.com/review/www.walmart.com?page=433\n",
            "Fetching page 434: https://www.trustpilot.com/review/www.walmart.com?page=434\n",
            "Fetching page 435: https://www.trustpilot.com/review/www.walmart.com?page=435\n",
            "Fetching page 436: https://www.trustpilot.com/review/www.walmart.com?page=436\n",
            "Fetching page 437: https://www.trustpilot.com/review/www.walmart.com?page=437\n",
            "Fetching page 438: https://www.trustpilot.com/review/www.walmart.com?page=438\n",
            "Fetching page 439: https://www.trustpilot.com/review/www.walmart.com?page=439\n",
            "Fetching page 440: https://www.trustpilot.com/review/www.walmart.com?page=440\n",
            "Fetching page 441: https://www.trustpilot.com/review/www.walmart.com?page=441\n",
            "Fetching page 442: https://www.trustpilot.com/review/www.walmart.com?page=442\n",
            "Fetching page 443: https://www.trustpilot.com/review/www.walmart.com?page=443\n",
            "Fetching page 444: https://www.trustpilot.com/review/www.walmart.com?page=444\n",
            "Fetching page 445: https://www.trustpilot.com/review/www.walmart.com?page=445\n",
            "Fetching page 446: https://www.trustpilot.com/review/www.walmart.com?page=446\n",
            "Fetching page 447: https://www.trustpilot.com/review/www.walmart.com?page=447\n",
            "Fetching page 448: https://www.trustpilot.com/review/www.walmart.com?page=448\n",
            "Fetching page 449: https://www.trustpilot.com/review/www.walmart.com?page=449\n",
            "Fetching page 450: https://www.trustpilot.com/review/www.walmart.com?page=450\n",
            "Fetching page 451: https://www.trustpilot.com/review/www.walmart.com?page=451\n",
            "Fetching page 452: https://www.trustpilot.com/review/www.walmart.com?page=452\n",
            "Fetching page 453: https://www.trustpilot.com/review/www.walmart.com?page=453\n",
            "Fetching page 454: https://www.trustpilot.com/review/www.walmart.com?page=454\n",
            "Fetching page 455: https://www.trustpilot.com/review/www.walmart.com?page=455\n",
            "Fetching page 456: https://www.trustpilot.com/review/www.walmart.com?page=456\n",
            "Fetching page 457: https://www.trustpilot.com/review/www.walmart.com?page=457\n",
            "Fetching page 458: https://www.trustpilot.com/review/www.walmart.com?page=458\n",
            "Fetching page 459: https://www.trustpilot.com/review/www.walmart.com?page=459\n",
            "Fetching page 460: https://www.trustpilot.com/review/www.walmart.com?page=460\n",
            "Fetching page 461: https://www.trustpilot.com/review/www.walmart.com?page=461\n",
            "Fetching page 462: https://www.trustpilot.com/review/www.walmart.com?page=462\n",
            "Fetching page 463: https://www.trustpilot.com/review/www.walmart.com?page=463\n",
            "Fetching page 464: https://www.trustpilot.com/review/www.walmart.com?page=464\n",
            "Fetching page 465: https://www.trustpilot.com/review/www.walmart.com?page=465\n",
            "Fetching page 466: https://www.trustpilot.com/review/www.walmart.com?page=466\n",
            "Fetching page 467: https://www.trustpilot.com/review/www.walmart.com?page=467\n",
            "Fetching page 468: https://www.trustpilot.com/review/www.walmart.com?page=468\n",
            "Fetching page 469: https://www.trustpilot.com/review/www.walmart.com?page=469\n",
            "Fetching page 470: https://www.trustpilot.com/review/www.walmart.com?page=470\n",
            "Fetching page 471: https://www.trustpilot.com/review/www.walmart.com?page=471\n",
            "Fetching page 472: https://www.trustpilot.com/review/www.walmart.com?page=472\n",
            "Fetching page 473: https://www.trustpilot.com/review/www.walmart.com?page=473\n",
            "Fetching page 474: https://www.trustpilot.com/review/www.walmart.com?page=474\n",
            "Fetching page 475: https://www.trustpilot.com/review/www.walmart.com?page=475\n",
            "Fetching page 476: https://www.trustpilot.com/review/www.walmart.com?page=476\n",
            "Fetching page 477: https://www.trustpilot.com/review/www.walmart.com?page=477\n",
            "Fetching page 478: https://www.trustpilot.com/review/www.walmart.com?page=478\n",
            "Fetching page 479: https://www.trustpilot.com/review/www.walmart.com?page=479\n",
            "Fetching page 480: https://www.trustpilot.com/review/www.walmart.com?page=480\n",
            "Fetching page 481: https://www.trustpilot.com/review/www.walmart.com?page=481\n",
            "Fetching page 482: https://www.trustpilot.com/review/www.walmart.com?page=482\n",
            "Fetching page 483: https://www.trustpilot.com/review/www.walmart.com?page=483\n",
            "Fetching page 484: https://www.trustpilot.com/review/www.walmart.com?page=484\n",
            "Fetching page 485: https://www.trustpilot.com/review/www.walmart.com?page=485\n",
            "Fetching page 486: https://www.trustpilot.com/review/www.walmart.com?page=486\n",
            "Fetching page 487: https://www.trustpilot.com/review/www.walmart.com?page=487\n",
            "Fetching page 488: https://www.trustpilot.com/review/www.walmart.com?page=488\n",
            "Fetching page 489: https://www.trustpilot.com/review/www.walmart.com?page=489\n",
            "Fetching page 490: https://www.trustpilot.com/review/www.walmart.com?page=490\n",
            "Fetching page 491: https://www.trustpilot.com/review/www.walmart.com?page=491\n",
            "Fetching page 492: https://www.trustpilot.com/review/www.walmart.com?page=492\n",
            "Fetching page 493: https://www.trustpilot.com/review/www.walmart.com?page=493\n",
            "Fetching page 494: https://www.trustpilot.com/review/www.walmart.com?page=494\n",
            "Fetching page 495: https://www.trustpilot.com/review/www.walmart.com?page=495\n",
            "Fetching page 496: https://www.trustpilot.com/review/www.walmart.com?page=496\n",
            "Fetching page 497: https://www.trustpilot.com/review/www.walmart.com?page=497\n",
            "Fetching page 498: https://www.trustpilot.com/review/www.walmart.com?page=498\n",
            "Fetching page 499: https://www.trustpilot.com/review/www.walmart.com?page=499\n",
            "Fetching page 500: https://www.trustpilot.com/review/www.walmart.com?page=500\n",
            "Fetching page 501: https://www.trustpilot.com/review/www.walmart.com?page=501\n",
            "Fetching page 502: https://www.trustpilot.com/review/www.walmart.com?page=502\n",
            "Fetching page 503: https://www.trustpilot.com/review/www.walmart.com?page=503\n",
            "Fetching page 504: https://www.trustpilot.com/review/www.walmart.com?page=504\n",
            "Fetching page 505: https://www.trustpilot.com/review/www.walmart.com?page=505\n",
            "Fetching page 506: https://www.trustpilot.com/review/www.walmart.com?page=506\n",
            "Fetching page 507: https://www.trustpilot.com/review/www.walmart.com?page=507\n",
            "Fetching page 508: https://www.trustpilot.com/review/www.walmart.com?page=508\n",
            "Fetching page 509: https://www.trustpilot.com/review/www.walmart.com?page=509\n",
            "Fetching page 510: https://www.trustpilot.com/review/www.walmart.com?page=510\n",
            "Fetching page 511: https://www.trustpilot.com/review/www.walmart.com?page=511\n",
            "Fetching page 512: https://www.trustpilot.com/review/www.walmart.com?page=512\n",
            "Fetching page 513: https://www.trustpilot.com/review/www.walmart.com?page=513\n",
            "          Username Total reviews                      Date  \\\n",
            "0                              3  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             3  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            19  2025-03-11T02:19:00.000Z   \n",
            "3               LA            27  2025-03-11T20:29:17.000Z   \n",
            "4           Laurie             1  2020-06-09T02:09:57.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  I am sick and tired of them not having…I am si...      3  \n",
            "1  My daughter recently did a self check…My daugh...      1  \n",
            "2  Total runaround trying to find my lost orderI ...      1  \n",
            "3  Braided rug disappointmentOrdered a braided ru...      3  \n",
            "4  Automotive center STILL closed and…Automotive ...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "60lCcNNyC4eL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JKUgJoKVC4pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 445 TO 476 PAGES"
      ],
      "metadata": {
        "id": "R7yHF09iC7gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 445\n",
        "to_page = 513\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "# List of user-agents to simulate different browsers\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n",
        "]\n",
        "\n",
        "# Function to fetch a page with retries in case of failure\n",
        "def fetch_page_with_retry(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        headers = {\n",
        "            \"User-Agent\": random.choice(user_agents)\n",
        "        }\n",
        "        try:\n",
        "            result = requests.get(url, headers=headers)\n",
        "            if result.status_code == 200:\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Failed to retrieve page. Status code: {result.status_code}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for {url}: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"Failed to retrieve {url} after {retries} retries.\")\n",
        "    return None  # Return None if all retries fail\n",
        "\n",
        "# Scraping the reviews from page 111 to 411\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    print(f\"Fetching page {i}: {url}\")\n",
        "\n",
        "    # Fetch the page with retry mechanism\n",
        "    result = fetch_page_with_retry(url)\n",
        "\n",
        "    if not result:\n",
        "        print(f\"Skipping page {i} due to repeated failures.\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# # Optionally save to CSV\n",
        "# review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJk9ibMC4zf",
        "outputId": "d1a87f81-2254-45e0-b69b-1052c80e6ac6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 445: https://www.trustpilot.com/review/www.walmart.com?page=445\n",
            "Fetching page 446: https://www.trustpilot.com/review/www.walmart.com?page=446\n",
            "Fetching page 447: https://www.trustpilot.com/review/www.walmart.com?page=447\n",
            "Fetching page 448: https://www.trustpilot.com/review/www.walmart.com?page=448\n",
            "Fetching page 449: https://www.trustpilot.com/review/www.walmart.com?page=449\n",
            "Fetching page 450: https://www.trustpilot.com/review/www.walmart.com?page=450\n",
            "Fetching page 451: https://www.trustpilot.com/review/www.walmart.com?page=451\n",
            "Fetching page 452: https://www.trustpilot.com/review/www.walmart.com?page=452\n",
            "Fetching page 453: https://www.trustpilot.com/review/www.walmart.com?page=453\n",
            "Fetching page 454: https://www.trustpilot.com/review/www.walmart.com?page=454\n",
            "Fetching page 455: https://www.trustpilot.com/review/www.walmart.com?page=455\n",
            "Fetching page 456: https://www.trustpilot.com/review/www.walmart.com?page=456\n",
            "Fetching page 457: https://www.trustpilot.com/review/www.walmart.com?page=457\n",
            "Fetching page 458: https://www.trustpilot.com/review/www.walmart.com?page=458\n",
            "Fetching page 459: https://www.trustpilot.com/review/www.walmart.com?page=459\n",
            "Fetching page 460: https://www.trustpilot.com/review/www.walmart.com?page=460\n",
            "Fetching page 461: https://www.trustpilot.com/review/www.walmart.com?page=461\n",
            "Fetching page 462: https://www.trustpilot.com/review/www.walmart.com?page=462\n",
            "Fetching page 463: https://www.trustpilot.com/review/www.walmart.com?page=463\n",
            "Fetching page 464: https://www.trustpilot.com/review/www.walmart.com?page=464\n",
            "Fetching page 465: https://www.trustpilot.com/review/www.walmart.com?page=465\n",
            "Fetching page 466: https://www.trustpilot.com/review/www.walmart.com?page=466\n",
            "Fetching page 467: https://www.trustpilot.com/review/www.walmart.com?page=467\n",
            "Fetching page 468: https://www.trustpilot.com/review/www.walmart.com?page=468\n",
            "Fetching page 469: https://www.trustpilot.com/review/www.walmart.com?page=469\n",
            "Fetching page 470: https://www.trustpilot.com/review/www.walmart.com?page=470\n",
            "Fetching page 471: https://www.trustpilot.com/review/www.walmart.com?page=471\n",
            "Fetching page 472: https://www.trustpilot.com/review/www.walmart.com?page=472\n",
            "Fetching page 473: https://www.trustpilot.com/review/www.walmart.com?page=473\n",
            "Fetching page 474: https://www.trustpilot.com/review/www.walmart.com?page=474\n",
            "Fetching page 475: https://www.trustpilot.com/review/www.walmart.com?page=475\n",
            "Fetching page 476: https://www.trustpilot.com/review/www.walmart.com?page=476\n",
            "Fetching page 477: https://www.trustpilot.com/review/www.walmart.com?page=477\n",
            "Fetching page 478: https://www.trustpilot.com/review/www.walmart.com?page=478\n",
            "Fetching page 479: https://www.trustpilot.com/review/www.walmart.com?page=479\n",
            "Fetching page 480: https://www.trustpilot.com/review/www.walmart.com?page=480\n",
            "Fetching page 481: https://www.trustpilot.com/review/www.walmart.com?page=481\n",
            "Fetching page 482: https://www.trustpilot.com/review/www.walmart.com?page=482\n",
            "Fetching page 483: https://www.trustpilot.com/review/www.walmart.com?page=483\n",
            "Fetching page 484: https://www.trustpilot.com/review/www.walmart.com?page=484\n",
            "Fetching page 485: https://www.trustpilot.com/review/www.walmart.com?page=485\n",
            "Fetching page 486: https://www.trustpilot.com/review/www.walmart.com?page=486\n",
            "Fetching page 487: https://www.trustpilot.com/review/www.walmart.com?page=487\n",
            "Fetching page 488: https://www.trustpilot.com/review/www.walmart.com?page=488\n",
            "Fetching page 489: https://www.trustpilot.com/review/www.walmart.com?page=489\n",
            "Fetching page 490: https://www.trustpilot.com/review/www.walmart.com?page=490\n",
            "Fetching page 491: https://www.trustpilot.com/review/www.walmart.com?page=491\n",
            "Fetching page 492: https://www.trustpilot.com/review/www.walmart.com?page=492\n",
            "Fetching page 493: https://www.trustpilot.com/review/www.walmart.com?page=493\n",
            "Fetching page 494: https://www.trustpilot.com/review/www.walmart.com?page=494\n",
            "Fetching page 495: https://www.trustpilot.com/review/www.walmart.com?page=495\n",
            "Fetching page 496: https://www.trustpilot.com/review/www.walmart.com?page=496\n",
            "Fetching page 497: https://www.trustpilot.com/review/www.walmart.com?page=497\n",
            "Fetching page 498: https://www.trustpilot.com/review/www.walmart.com?page=498\n",
            "Fetching page 499: https://www.trustpilot.com/review/www.walmart.com?page=499\n",
            "Fetching page 500: https://www.trustpilot.com/review/www.walmart.com?page=500\n",
            "Fetching page 501: https://www.trustpilot.com/review/www.walmart.com?page=501\n",
            "Fetching page 502: https://www.trustpilot.com/review/www.walmart.com?page=502\n",
            "Fetching page 503: https://www.trustpilot.com/review/www.walmart.com?page=503\n",
            "Fetching page 504: https://www.trustpilot.com/review/www.walmart.com?page=504\n",
            "Fetching page 505: https://www.trustpilot.com/review/www.walmart.com?page=505\n",
            "Fetching page 506: https://www.trustpilot.com/review/www.walmart.com?page=506\n",
            "Fetching page 507: https://www.trustpilot.com/review/www.walmart.com?page=507\n",
            "Fetching page 508: https://www.trustpilot.com/review/www.walmart.com?page=508\n",
            "Fetching page 509: https://www.trustpilot.com/review/www.walmart.com?page=509\n",
            "Fetching page 510: https://www.trustpilot.com/review/www.walmart.com?page=510\n",
            "Fetching page 511: https://www.trustpilot.com/review/www.walmart.com?page=511\n",
            "Fetching page 512: https://www.trustpilot.com/review/www.walmart.com?page=512\n",
            "Fetching page 513: https://www.trustpilot.com/review/www.walmart.com?page=513\n",
            "          Username Total reviews                      Date  \\\n",
            "0                              3  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             3  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            19  2025-03-11T02:19:00.000Z   \n",
            "3               LA            29  2025-03-11T20:29:17.000Z   \n",
            "4           Laurie             1  2019-12-03T08:56:12.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  Honestly would give it the zero Stars…Honestly...      1  \n",
            "1  doesn't even deserve a stardoesn't even deserv...      1  \n",
            "2  Ordered something online and they…Ordered some...      1  \n",
            "3  The store 2287 in New Castle Pa is…The store 2...      2  \n",
            "4  Would put negative stars if I couldWould put n...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6m6CZ8R0C43A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 477 TO 497 PAGES"
      ],
      "metadata": {
        "id": "RrVFS8gBEIQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 477\n",
        "to_page = 513\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "# List of user-agents to simulate different browsers\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n",
        "]\n",
        "\n",
        "# Function to fetch a page with retries in case of failure\n",
        "def fetch_page_with_retry(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        headers = {\n",
        "            \"User-Agent\": random.choice(user_agents)\n",
        "        }\n",
        "        try:\n",
        "            result = requests.get(url, headers=headers)\n",
        "            if result.status_code == 200:\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Failed to retrieve page. Status code: {result.status_code}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for {url}: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"Failed to retrieve {url} after {retries} retries.\")\n",
        "    return None  # Return None if all retries fail\n",
        "\n",
        "# Scraping the reviews from page 111 to 411\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    print(f\"Fetching page {i}: {url}\")\n",
        "\n",
        "    # Fetch the page with retry mechanism\n",
        "    result = fetch_page_with_retry(url)\n",
        "\n",
        "    if not result:\n",
        "        print(f\"Skipping page {i} due to repeated failures.\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# # Optionally save to CSV\n",
        "# review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1axxfVuC5eH",
        "outputId": "6c4f71f8-b494-4327-cb49-52ea3d7329cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 477: https://www.trustpilot.com/review/www.walmart.com?page=477\n",
            "Fetching page 478: https://www.trustpilot.com/review/www.walmart.com?page=478\n",
            "Fetching page 479: https://www.trustpilot.com/review/www.walmart.com?page=479\n",
            "Fetching page 480: https://www.trustpilot.com/review/www.walmart.com?page=480\n",
            "Fetching page 481: https://www.trustpilot.com/review/www.walmart.com?page=481\n",
            "Fetching page 482: https://www.trustpilot.com/review/www.walmart.com?page=482\n",
            "Fetching page 483: https://www.trustpilot.com/review/www.walmart.com?page=483\n",
            "Fetching page 484: https://www.trustpilot.com/review/www.walmart.com?page=484\n",
            "Fetching page 485: https://www.trustpilot.com/review/www.walmart.com?page=485\n",
            "Fetching page 486: https://www.trustpilot.com/review/www.walmart.com?page=486\n",
            "Fetching page 487: https://www.trustpilot.com/review/www.walmart.com?page=487\n",
            "Fetching page 488: https://www.trustpilot.com/review/www.walmart.com?page=488\n",
            "Fetching page 489: https://www.trustpilot.com/review/www.walmart.com?page=489\n",
            "Fetching page 490: https://www.trustpilot.com/review/www.walmart.com?page=490\n",
            "Fetching page 491: https://www.trustpilot.com/review/www.walmart.com?page=491\n",
            "Fetching page 492: https://www.trustpilot.com/review/www.walmart.com?page=492\n",
            "Fetching page 493: https://www.trustpilot.com/review/www.walmart.com?page=493\n",
            "Fetching page 494: https://www.trustpilot.com/review/www.walmart.com?page=494\n",
            "Fetching page 495: https://www.trustpilot.com/review/www.walmart.com?page=495\n",
            "Fetching page 496: https://www.trustpilot.com/review/www.walmart.com?page=496\n",
            "Fetching page 497: https://www.trustpilot.com/review/www.walmart.com?page=497\n",
            "Fetching page 498: https://www.trustpilot.com/review/www.walmart.com?page=498\n",
            "Fetching page 499: https://www.trustpilot.com/review/www.walmart.com?page=499\n",
            "Fetching page 500: https://www.trustpilot.com/review/www.walmart.com?page=500\n",
            "Fetching page 501: https://www.trustpilot.com/review/www.walmart.com?page=501\n",
            "Fetching page 502: https://www.trustpilot.com/review/www.walmart.com?page=502\n",
            "Fetching page 503: https://www.trustpilot.com/review/www.walmart.com?page=503\n",
            "Fetching page 504: https://www.trustpilot.com/review/www.walmart.com?page=504\n",
            "Fetching page 505: https://www.trustpilot.com/review/www.walmart.com?page=505\n",
            "Fetching page 506: https://www.trustpilot.com/review/www.walmart.com?page=506\n",
            "Fetching page 507: https://www.trustpilot.com/review/www.walmart.com?page=507\n",
            "Fetching page 508: https://www.trustpilot.com/review/www.walmart.com?page=508\n",
            "Fetching page 509: https://www.trustpilot.com/review/www.walmart.com?page=509\n",
            "Fetching page 510: https://www.trustpilot.com/review/www.walmart.com?page=510\n",
            "Fetching page 511: https://www.trustpilot.com/review/www.walmart.com?page=511\n",
            "Fetching page 512: https://www.trustpilot.com/review/www.walmart.com?page=512\n",
            "Fetching page 513: https://www.trustpilot.com/review/www.walmart.com?page=513\n",
            "          Username Total reviews                      Date  \\\n",
            "0                              3  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             4  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            19  2025-03-11T02:19:00.000Z   \n",
            "3               LA           N/A  2025-03-11T20:29:17.000Z   \n",
            "4           Laurie            28  2019-03-20T05:51:22.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  Order (2) TVs from Walmart.com and paid…Order ...      1  \n",
            "1  I ordered 2 cages for a total of 399.00…I orde...      1  \n",
            "2  Seems as though the site is getting…Seems as t...      3  \n",
            "3  Savings Catcher and ShoppingRecently I receive...      1  \n",
            "4  Thank god for a walmartThank god for a walmart...      5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLy5_AL-E2-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SCRAPING 498 TO 513 PAGES"
      ],
      "metadata": {
        "id": "rKenR1vBFNJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "\n",
        "# Function to extract data from BeautifulSoup objects\n",
        "def soup2list(src, list_, attr=None):\n",
        "    if attr:\n",
        "        for val in src:\n",
        "            list_.append(val.get(attr, \"N/A\"))  # Avoid KeyError if attribute is missing\n",
        "    else:\n",
        "        for val in src:\n",
        "            list_.append(val.get_text(strip=True))  # Strip spaces\n",
        "\n",
        "# Lists to store extracted data\n",
        "users = []\n",
        "userReviewNum = []\n",
        "ratings = []\n",
        "locations = []\n",
        "dates = []\n",
        "reviews = []\n",
        "\n",
        "from_page = 498\n",
        "to_page = 513\n",
        "company = 'www.walmart.com'\n",
        "\n",
        "# List of user-agents to simulate different browsers\n",
        "user_agents = [\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
        "    \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0\",\n",
        "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0\",\n",
        "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.88 Safari/537.36\"\n",
        "]\n",
        "\n",
        "# Function to fetch a page with retries in case of failure\n",
        "def fetch_page_with_retry(url, retries=5):\n",
        "    for _ in range(retries):\n",
        "        headers = {\n",
        "            \"User-Agent\": random.choice(user_agents)\n",
        "        }\n",
        "        try:\n",
        "            result = requests.get(url, headers=headers)\n",
        "            if result.status_code == 200:\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Failed to retrieve page. Status code: {result.status_code}. Retrying...\")\n",
        "                time.sleep(5)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Request error for {url}: {e}. Retrying...\")\n",
        "            time.sleep(5)\n",
        "\n",
        "    print(f\"Failed to retrieve {url} after {retries} retries.\")\n",
        "    return None  # Return None if all retries fail\n",
        "\n",
        "# Scraping the reviews from page 111 to 411\n",
        "for i in range(from_page, to_page + 1):\n",
        "    url = f\"https://www.trustpilot.com/review/{company}?page={i}\"\n",
        "    print(f\"Fetching page {i}: {url}\")\n",
        "\n",
        "    # Fetch the page with retry mechanism\n",
        "    result = fetch_page_with_retry(url)\n",
        "\n",
        "    if not result:\n",
        "        print(f\"Skipping page {i} due to repeated failures.\")\n",
        "        continue  # Skip this page if request fails\n",
        "\n",
        "    soup = BeautifulSoup(result.content, \"html.parser\")\n",
        "\n",
        "    # Extracting Usernames\n",
        "    soup2list(soup.find_all('span', class_='typography_heading-xs__osRhC'), users)  # Usernames\n",
        "\n",
        "    # Extracting Total Reviews (Numbers only)\n",
        "    for user_info in soup.find_all('div', class_='styles_consumerExtraDetails__TylYM'):\n",
        "        total_reviews_text = user_info.get_text(strip=True)\n",
        "        total_reviews = ''.join(filter(str.isdigit, total_reviews_text))  # Extract digits only\n",
        "        userReviewNum.append(total_reviews if total_reviews else \"N/A\")\n",
        "\n",
        "    # Extracting Dates\n",
        "    soup2list(soup.find_all('time'), dates, attr='datetime')  # Dates\n",
        "\n",
        "    # Extracting Ratings\n",
        "    soup2list(soup.find_all('div', class_='styles_reviewHeader__PuHBd'), ratings, attr='data-service-review-rating')  # Ratings\n",
        "\n",
        "    # Extracting Review Texts\n",
        "    for review_content in soup.find_all('div', class_='styles_reviewContent__SCYfD'):\n",
        "        review_text = review_content.get_text(strip=True)\n",
        "        reviews.append(review_text if review_text else \"N/A\")\n",
        "\n",
        "    sleep(1)  # Prevents request throttling\n",
        "\n",
        "# Fix: Ensure all lists have the same length\n",
        "max_length = max(len(users), len(userReviewNum), len(locations), len(dates), len(reviews), len(ratings))\n",
        "\n",
        "# Pad shorter lists with \"N/A\"\n",
        "users += [\"N/A\"] * (max_length - len(users))\n",
        "userReviewNum += [\"N/A\"] * (max_length - len(userReviewNum))\n",
        "dates += [\"N/A\"] * (max_length - len(dates))\n",
        "reviews += [\"N/A\"] * (max_length - len(reviews))\n",
        "ratings += [\"N/A\"] * (max_length - len(ratings))\n",
        "\n",
        "# Creating a DataFrame\n",
        "review_data = pd.DataFrame(\n",
        "    {\n",
        "        'Username': users,\n",
        "        'Total reviews': userReviewNum,\n",
        "        'Date': dates,\n",
        "        'Review': reviews,\n",
        "        'Rating': ratings\n",
        "    }\n",
        ")\n",
        "\n",
        "# # Optionally save to CSV\n",
        "# review_data.to_csv(\"review_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows for debugging purposes\n",
        "print(review_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZes0DRtE3Kd",
        "outputId": "619f8acf-dbab-4564-d96f-1cdbf5ae392d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching page 498: https://www.trustpilot.com/review/www.walmart.com?page=498\n",
            "Fetching page 499: https://www.trustpilot.com/review/www.walmart.com?page=499\n",
            "Fetching page 500: https://www.trustpilot.com/review/www.walmart.com?page=500\n",
            "Fetching page 501: https://www.trustpilot.com/review/www.walmart.com?page=501\n",
            "Fetching page 502: https://www.trustpilot.com/review/www.walmart.com?page=502\n",
            "Fetching page 503: https://www.trustpilot.com/review/www.walmart.com?page=503\n",
            "Fetching page 504: https://www.trustpilot.com/review/www.walmart.com?page=504\n",
            "Fetching page 505: https://www.trustpilot.com/review/www.walmart.com?page=505\n",
            "Fetching page 506: https://www.trustpilot.com/review/www.walmart.com?page=506\n",
            "Fetching page 507: https://www.trustpilot.com/review/www.walmart.com?page=507\n",
            "Fetching page 508: https://www.trustpilot.com/review/www.walmart.com?page=508\n",
            "Fetching page 509: https://www.trustpilot.com/review/www.walmart.com?page=509\n",
            "Fetching page 510: https://www.trustpilot.com/review/www.walmart.com?page=510\n",
            "Fetching page 511: https://www.trustpilot.com/review/www.walmart.com?page=511\n",
            "Fetching page 512: https://www.trustpilot.com/review/www.walmart.com?page=512\n",
            "Fetching page 513: https://www.trustpilot.com/review/www.walmart.com?page=513\n",
            "          Username Total reviews                      Date  \\\n",
            "0                              3  2025-03-09T00:02:13.000Z   \n",
            "1    Madeline Hall             4  2025-03-11T17:46:12.000Z   \n",
            "2  Christy Mashore            19  2025-03-11T02:19:00.000Z   \n",
            "3               LA           N/A  2025-03-11T20:29:17.000Z   \n",
            "4           Laurie             2  2017-12-15T22:43:26.000Z   \n",
            "\n",
            "                                              Review Rating  \n",
            "0  After experience in the Center Texas …After ex...      1  \n",
            "1  Walmart is greatWalmart is great! I ordered fr...      5  \n",
            "2  WALMART  On line ordering is a scam.  NO SAVIN...      1  \n",
            "3  Great store and peopleDate of experience:Decem...      5  \n",
            "4  Ordered video game on sale to pick-up …Ordered...      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5esecmUFYXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XYJ6jiaRE3N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "-tcBUgjQWxXd",
        "outputId": "fa580abe-a896-4363-ea05-5fdc90f98ab7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           Username Total reviews  \\\n",
              "0                                                               3   \n",
              "1                                     Madeline Hall             4   \n",
              "2                                   Christy Mashore            19   \n",
              "3                                                LA           N/A   \n",
              "4                                            Laurie             2   \n",
              "..                                              ...           ...   \n",
              "662                                           chiru           N/A   \n",
              "663                                              PS           N/A   \n",
              "664                                       priya sen           N/A   \n",
              "665  Show reviews in all languages. (10,872reviews)           N/A   \n",
              "666                              Take a closer look           N/A   \n",
              "\n",
              "                         Date  \\\n",
              "0    2025-03-09T00:02:13.000Z   \n",
              "1    2025-03-11T17:46:12.000Z   \n",
              "2    2025-03-11T02:19:00.000Z   \n",
              "3    2025-03-11T20:29:17.000Z   \n",
              "4    2017-12-15T22:43:26.000Z   \n",
              "..                        ...   \n",
              "662                       N/A   \n",
              "663                       N/A   \n",
              "664                       N/A   \n",
              "665                       N/A   \n",
              "666                       N/A   \n",
              "\n",
              "                                                Review Rating  \n",
              "0    After experience in the Center Texas …After ex...      1  \n",
              "1    Walmart is greatWalmart is great! I ordered fr...      5  \n",
              "2    WALMART  On line ordering is a scam.  NO SAVIN...      1  \n",
              "3    Great store and peopleDate of experience:Decem...      5  \n",
              "4    Ordered video game on sale to pick-up …Ordered...      1  \n",
              "..                                                 ...    ...  \n",
              "662                                                N/A    N/A  \n",
              "663                                                N/A    N/A  \n",
              "664                                                N/A    N/A  \n",
              "665                                                N/A    N/A  \n",
              "666                                                N/A    N/A  \n",
              "\n",
              "[667 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7db02ec4-a8e0-44b2-82fd-50f3b8770328\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username</th>\n",
              "      <th>Total reviews</th>\n",
              "      <th>Date</th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>3</td>\n",
              "      <td>2025-03-09T00:02:13.000Z</td>\n",
              "      <td>After experience in the Center Texas …After ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Madeline Hall</td>\n",
              "      <td>4</td>\n",
              "      <td>2025-03-11T17:46:12.000Z</td>\n",
              "      <td>Walmart is greatWalmart is great! I ordered fr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Christy Mashore</td>\n",
              "      <td>19</td>\n",
              "      <td>2025-03-11T02:19:00.000Z</td>\n",
              "      <td>WALMART  On line ordering is a scam.  NO SAVIN...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LA</td>\n",
              "      <td>N/A</td>\n",
              "      <td>2025-03-11T20:29:17.000Z</td>\n",
              "      <td>Great store and peopleDate of experience:Decem...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Laurie</td>\n",
              "      <td>2</td>\n",
              "      <td>2017-12-15T22:43:26.000Z</td>\n",
              "      <td>Ordered video game on sale to pick-up …Ordered...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>chiru</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>PS</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>priya sen</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>Show reviews in all languages. (10,872reviews)</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>Take a closer look</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>667 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7db02ec4-a8e0-44b2-82fd-50f3b8770328')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7db02ec4-a8e0-44b2-82fd-50f3b8770328 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7db02ec4-a8e0-44b2-82fd-50f3b8770328');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acf077fd-7f4a-493a-8ea2-d8c0d55a11fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acf077fd-7f4a-493a-8ea2-d8c0d55a11fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acf077fd-7f4a-493a-8ea2-d8c0d55a11fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0ae734f0-30c6-4d55-8d11-853e96d7dd9d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('review_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0ae734f0-30c6-4d55-8d11-853e96d7dd9d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('review_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "review_data",
              "summary": "{\n  \"name\": \"review_data\",\n  \"rows\": 667,\n  \"fields\": [\n    {\n      \"column\": \"Username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 450,\n        \"samples\": [\n          \"JL\",\n          \"Diana Potter\",\n          \"Yoczelin Janeli Avalos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total reviews\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"6\",\n          \"58\",\n          \"3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 321,\n        \"samples\": [\n          \"2016-10-12T15:25:06.000Z\",\n          \"2017-03-25T12:18:44.000Z\",\n          \"2016-07-19T23:02:54.000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 317,\n        \"samples\": [\n          \"They said someone had signed for my packageI've ordered from Walmart for years without problem however in the last 2 weeks I've had an order that was damaged and sent back, few days later still no update on my order and no refund. I had to contact them and they gave me a refund for it.  I had another order sent to I don't know where, I hadn't realized till 2 days later. I called Walmart and this time I told them I wanted the items replaced. They said someone had signed for my package, a package that wasn't authorized for a signature. The name was an odd one so odd that it seemed made up, It had 2 letter F's next to each other and 2 letter i's next to each other. They told me to ask my neighbors and contact FedEx. That told me I was screwed. The the items were under $10 but needed. If this could happen with that order, I don't believe I can trust them with something more expensive.Date of experience:July 08, 2017\",\n          \"Walmart Customer Care cannot care for real problemsI have ordered some times from Walmart, using Paypal, and it has gone well. Now, for some reason, purchasing a giftcard, worth 20$, my account is being flagged. And nobody can tell me why, and all I get is the same standard replies when I write Customer Care. That has been going on for 3 weeks now. Paypal has accepted, and I use Paypal frequently, so it is with Walmart. Walmart wants in on th e-commerce - they need to shape up with Customer Care, and have qualified people handling customer issues.Very dissatisfied with the Walmart Customer Care!!Date of experience:December 18, 2013\",\n          \"I love WalmartI love Walmart. Com specially the saving catcherDate of experience:October 25, 2017\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"1\",\n          \"5\",\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the DataFrame to a CSV file and download it\n",
        "\n",
        "review_data.to_csv('reviews.csv', index=False)\n",
        "files.download('reviews.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lb1wdUGUWxaZ",
        "outputId": "dd411d9c-2766-4588-fd56-dcd962bce088"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1da4fc52-7573-4096-8f93-e1f3748a70b9\", \"reviews.csv\", 186605)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7R3wZdIAT7S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}